{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Навигация по уроку**\n",
        "\n",
        "1. [Первое знакомство с AutoML](https://colab.research.google.com/drive/1bCWyzlp1-tcvt7TE60m4hFnRd5AWscWY)\n",
        "2. [Гиперпараметры и оптимизация моделей](https://colab.research.google.com/drive/1CN69NftfVXUliyv11FGbM7qOYbO0XON5)\n",
        "3. [AutoML в Keras](https://colab.research.google.com/drive/1V7mfY8da0S-FbWxhQbchJM38JSJBmtoZ)\n",
        "4. Домашняя работа"
      ],
      "metadata": {
        "id": "OkPiPBslB9nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В домашней работе необходимо с помощью AutoKeras или KerasTuner найти оптимальную модель для решения одной из следующей задач:\n",
        "\n",
        "1. На 3 балла. Обучите модель с точностью не менее 90% предсказывать сарказм в новостных заголовках. Составьте 5 произвольных заголовков, которых нет в датасете и проверьте на них обученную модель, сделайте выводы. Ссылка на [датасет](https://storage.yandexcloud.net/academy.ai/Sarcasm_Headlines_Dataset_v2.json.zip).\n",
        "2. На 4 балла. Используйте [русский корпус новостей от Lenta.ru](https://www.kaggle.com/datasets/yutkin/corpus-of-russian-news-articles-from-lenta/data) подберите и обучите модель классифицировать новости по заголовкам на классы (поле topic в датасете). Используйте 9 самых часто встречаемых топиков и 10-й для остальных, не вошедших в 9 классов. Оцените модель с помощью отчета о классификации, сделайте выводы.  \n",
        "3. На 5 баллов. Найдите публичный датасет по обращениям граждан в администрацию, техническую поддержку или за консультацией. Обучите модель классифицировать обращения по тематикам. Сформируйте отчет о классификации и матрицу ошибок."
      ],
      "metadata": {
        "id": "W-cexaowCTp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras==1.1.0 tensorflow==2.15.1 keras-nlp==0.5.1"
      ],
      "metadata": {
        "id": "LWy8rP8Lg3ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp as nlp\n",
        "\n",
        "# Библиотека матричного вычисления\n",
        "import numpy as np\n",
        "# Библиотека для работы с данными\n",
        "import pandas as pd\n",
        "# Библиотека для работы с регулярными выражениями\n",
        "import re\n",
        "# Библиотека для работы с фреймворком TensorFlow\n",
        "import tensorflow as tf\n",
        "# Библиотека AutoML autokeras\n",
        "import autokeras as ak\n",
        "# Библиотеки для построения графиков и их стилизации\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Утилита для расщепления выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Необходимые метрики для построения Матрицы ошибок и отчета о классификации\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "x0UdV81Lg4Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SR5F_RCjhDbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qo \"/content/drive/MyDrive/Consumer_Complaints.csv.zip\" -d ./dataset"
      ],
      "metadata": {
        "id": "HqnJaS58hE2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address = \"./dataset/Consumer_Complaints.csv\""
      ],
      "metadata": {
        "id": "ZsezBYaqhGSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(address)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "isKXNDYjhKya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет состоит из:\n",
        "\n",
        "Date received — Дата получения\\\n",
        "Product — Продукт\\\n",
        "Sub-product — Подпродукт\\\n",
        "Issue — Проблема\\\n",
        "Sub-issue — Подпроблема\\\n",
        "Consumer complaint narrative — Текст жалобы потребителя\\\n",
        "Company public response — Публичный ответ компании\\\n",
        "Company — Компания\\\n",
        "State — Штат\\\n",
        "ZIP code — Почтовый индекс\\\n",
        "Tags — Метки\\\n",
        "Consumer consent provided? — Предоставлено согласие потребителя?\\\n",
        "Submitted via — Подано через\\\n",
        "Date sent to company — Дата отправки компании\\\n",
        "Company response to consumer — Ответ компании потребителю\\\n",
        "Timely response? — Своевременный ответ?\\\n",
        "Consumer disputed? — Оспорено потребителем?\\\n",
        "Complaint ID — Идентификатор жалобы"
      ],
      "metadata": {
        "id": "xzG8nxkihPG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление строк, где отсутствует текст жалобы потребителя или проблема\n",
        "df = df.dropna(subset=[\"Consumer complaint narrative\", \"Issue\"])"
      ],
      "metadata": {
        "id": "0xCES9-y1xeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистка текста\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n', ' ', text)  # Удаляем переносы строк\n",
        "    text = re.sub(r'\\r', ' ', text)  # Удаляем возвраты каретки\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Удаляем пунктуацию\n",
        "    text = re.sub(r'\\d+', '', text)  # Удаляем цифры\n",
        "    text = text.lower()  # Преобразуем текст к нижнему регистру\n",
        "    return text\n",
        "\n",
        "df[\"Consumer complaint narrative\"] = df[\"Consumer complaint narrative\"].apply(lambda x: clean_text(x) if isinstance(x, str) else x)\n",
        "df[\"Issue\"] = df[\"Issue\"].apply(lambda x: clean_text(x) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "ww6wXUZ60RbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраним оригинальные метки\n",
        "original_categories = df[\"Issue\"].astype(\"category\").cat.categories"
      ],
      "metadata": {
        "id": "A0t71PqYrLnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим порог для минимального количества примеров в категории\n",
        "min_samples = 2\n",
        "\n",
        "# Найдем категории с малым количеством примеров\n",
        "value_counts = df['Issue'].value_counts()\n",
        "to_remove = value_counts[value_counts < min_samples].index\n",
        "\n",
        "# Удалим строки с редкими категориями\n",
        "df = df[~df['Issue'].isin(to_remove)]"
      ],
      "metadata": {
        "id": "I1EqPW8Q3-T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование категорий в числовой формат\n",
        "df['Issue'] = pd.Categorical(df.Issue.to_numpy())\n",
        "df['Issue'] = df.Issue.cat.codes"
      ],
      "metadata": {
        "id": "nrMVe68s0cxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Issue.unique()"
      ],
      "metadata": {
        "id": "pU_mX-Va3Nom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обновляем переменные X и y\n",
        "X = df[\"Consumer complaint narrative\"].to_numpy()\n",
        "y = df.Issue.to_numpy()"
      ],
      "metadata": {
        "id": "AVgEpojn37_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую, валидационную и тестовую выборки\n",
        "X_tr, X_tmp, y_tr, y_tmp = train_test_split(X, y, stratify=y, test_size=0.3, random_state=15)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=15)"
      ],
      "metadata": {
        "id": "gF0ZCTBY3Lgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Форма входных данных: ', X_tr.shape)\n",
        "print('Форма выходных меток: ', y_tr.shape)\n",
        "print('Пример заголовка: ', X_tr[0])"
      ],
      "metadata": {
        "id": "KYc-uX_l5grF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock()(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "clf_mod = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True,  max_trials=2, objective='val_accuracy'\n",
        ")\n",
        "\n",
        "res = clf_mod.fit(X_tr, y_tr, epochs=10)"
      ],
      "metadata": {
        "id": "marU_ACp42zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_mod.export_model().summary()"
      ],
      "metadata": {
        "id": "JZ_CFhQ4ZsLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf_mod.predict(X_test).astype(int)\n",
        "\n",
        "print(clf_mod.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "x7_r7Oa9ZvBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_issues_text = pd.Categorical.from_codes(preds.flatten(), categories=original_categories)"
      ],
      "metadata": {
        "id": "sQbniJasrYWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame({'Consumer complaint narrative': X_test, 'Predicted Issue': predicted_issues_text})"
      ],
      "metadata": {
        "id": "5HCrkFmapU6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление предсказанных значений в DataFrame\n",
        "df_test['Predicted Issue'] = preds"
      ],
      "metadata": {
        "id": "EOEUuPXxqaSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "V2U8FoVdqeTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итог: Точность модели составила 40%, учитывая сложность данных датасета, количество меток, а так же различный формат обращений"
      ],
      "metadata": {
        "id": "jjEt8Ss1q0G_"
      }
    }
  ]
}